# API de Reconhecimento Autom√°tico de Emo√ß√µes

Esta API foi desenvolvida para reconhecer emo√ß√µes em frases curtas utilizando t√©cnicas de Processamento de Linguagem Natural (NLP) e Machine Learning. O sistema recebe uma frase via endpoint REST e retorna a emo√ß√£o predominante detectada.

## Vis√£o Geral

A API √© capaz de classificar textos em diferentes categorias emocionais como alegria, tristeza, raiva, medo, surpresa e neutro. O modelo foi treinado utilizando datasets p√∫blicos e implementado em Python com Flask para servir os endpoints.

## Tecnologias Utilizadas

- **Python 3.8+**
- **Flask** - Framework web para cria√ß√£o da API
- **scikit-learn** - Biblioteca de Machine Learning
- **NLTK** - Processamento de linguagem natural
- **pandas** - Manipula√ß√£o de dados
- **numpy** - Computa√ß√£o num√©rica
- **Google Colab** - Ambiente de desenvolvimento

## 1. Coleta e Limpeza dos Textos

### Origem dos Dados
Os dados utilizados para treinar o modelo prov√™m de datasets p√∫blicos que cont√™m frases rotuladas com suas respectivas emo√ß√µes:

- **Formato**: Arquivos CSV com colunas 'text' e 'emotion'
- **Volume**: Aproximadamente 20.000 frases distribu√≠das entre 6 categorias emocionais
- **Idioma**: Portugu√™s brasileiro
- **Distribui√ß√£o**: 
  - Alegria: ~4.000 exemplos
  - Tristeza: ~3.500 exemplos
  - Raiva: ~3.200 exemplos
  - Medo: ~3.000 exemplos
  - Surpresa: ~3.100 exemplos
  - Neutro: ~3.200 exemplos

### Processo de Limpeza
A limpeza dos textos segue uma pipeline estruturada para padronizar e otimizar os dados:

1. **Convers√£o para min√∫sculas**: Uniformiza o texto
2. **Remo√ß√£o de pontua√ß√£o**: Remove caracteres especiais (!@#$%^&*().,;:)
3. **Remo√ß√£o de n√∫meros**: Elimina d√≠gitos que n√£o agregam valor emocional
4. **Remo√ß√£o de stopwords**: Elimina palavras comuns sem valor sem√¢ntico (de, da, para, com, etc.)
5. **Remo√ß√£o de espa√ßos extras**: Normaliza espa√ßamentos
6. **Tratamento de caracteres especiais**: Remove acentos e caracteres n√£o-ASCII opcionalmente

### Exemplo de Limpeza
```
Texto original: "Estou MUITO feliz hoje!!! üòä Que dia maravilhoso..."
Texto limpo: "estou muito feliz hoje dia maravilhoso"

Texto original: "N√£o consigo acreditar que isso aconteceu comigo... üò¢"
Texto limpo: "consigo acreditar aconteceu comigo"
```

### C√≥digo de Limpeza
```python
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

def clean_text(text):
    # Converter para min√∫sculas
    text = text.lower()
    
    # Remover pontua√ß√£o e n√∫meros
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    
    # Tokenizar
    tokens = word_tokenize(text)
    
    # Remover stopwords
    stop_words = set(stopwords.words('portuguese'))
    tokens = [token for token in tokens if token not in stop_words]
    
    # Rejuntar tokens
    return ' '.join(tokens)
```

## 2. Vetoriza√ß√£o dos Textos

### O que √© Vetoriza√ß√£o?
A vetoriza√ß√£o √© o processo de converter texto em representa√ß√µes num√©ricas que algoritmos de Machine Learning podem processar. Como computadores n√£o entendem palavras diretamente, precisamos transformar o texto em vetores num√©ricos que capturem o significado e as caracter√≠sticas sem√¢nticas das frases.

### T√©cnicas de Vetoriza√ß√£o Utilizadas

#### TF-IDF (Term Frequency-Inverse Document Frequency)
A t√©cnica principal utilizada √© o TF-IDF, que considera:
- **TF (Term Frequency)**: Frequ√™ncia de uma palavra em um documento
- **IDF (Inverse Document Frequency)**: Raridade da palavra no corpus completo

**F√≥rmula**: TF-IDF = TF √ó log(N/DF)
- N = n√∫mero total de documentos
- DF = n√∫mero de documentos que cont√™m a palavra

#### Configura√ß√£o do Vetorizador
```python
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(
    max_features=5000,      # M√°ximo 5000 palavras mais importantes
    min_df=2,              # Palavra deve aparecer em pelo menos 2 documentos
    max_df=0.8,            # Palavra n√£o pode aparecer em mais de 80% dos documentos
    ngram_range=(1, 2)     # Considera unigramas e bigramas
)
```

### Exemplo de Vetoriza√ß√£o
```
Texto: "estou muito feliz hoje"
Vocabul√°rio: ['estou', 'muito', 'feliz', 'hoje', 'triste', 'raiva', ...]

Vetor TF-IDF: [0.52, 0.34, 0.78, 0.41, 0.0, 0.0, ...]
                ‚Üë     ‚Üë     ‚Üë     ‚Üë     ‚Üë    ‚Üë
             estou muito feliz hoje triste raiva
```

### Matriz de Caracter√≠sticas
Para um dataset com 1000 frases e vocabul√°rio de 5000 palavras:
```
Forma da matriz: (1000, 5000)
- Linhas: cada frase do dataset
- Colunas: cada palavra do vocabul√°rio
- Valores: pontua√ß√£o TF-IDF de cada palavra em cada frase
```

## 3. Treinamento do Modelo

### Divis√£o do Dataset
O dataset foi dividido estrategicamente para garantir avalia√ß√£o robusta:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_vectorized, y_labels, 
    test_size=0.2,        # 20% para teste
    random_state=42,      # Reproducibilidade
    stratify=y_labels     # Mant√©m propor√ß√£o das classes
)
```

**Distribui√ß√£o**:
- **Treino**: 80% (16.000 frases)
- **Teste**: 20% (4.000 frases)
- **Valida√ß√£o**: Utilizamos valida√ß√£o cruzada k-fold (k=5)

### Algoritmos Utilizados

#### 1. Naive Bayes Multinomial
**Funcionamento**: Baseado no teorema de Bayes, assume independ√™ncia entre as caracter√≠sticas. Calcula a probabilidade de cada classe dados os recursos de entrada.

**Vantagens**:
- R√°pido para treinar e prever
- Funciona bem com dados esparsos (como TF-IDF)
- Menos propenso a overfitting

**F√≥rmula**: P(classe|texto) = P(texto|classe) √ó P(classe) / P(texto)

#### 2. Random Forest
**Funcionamento**: Ensemble de m√∫ltiplas √°rvores de decis√£o. Cada √°rvore √© treinada com uma amostra aleat√≥ria dos dados e caracter√≠sticas.

**Vantagens**:
- Reduz overfitting
- Fornece import√¢ncia das caracter√≠sticas
- Robusto a outliers

**Configura√ß√£o**:
```python
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(
    n_estimators=100,      # 100 √°rvores
    max_depth=20,          # Profundidade m√°xima
    min_samples_split=5,   # M√≠nimo para dividir n√≥
    random_state=42
)
```

#### 3. Support Vector Machine (SVM)
**Funcionamento**: Encontra o hiperplano que melhor separa as classes maximizando a margem entre elas.

**Configura√ß√£o**:
```python
from sklearn.svm import SVC

svm_model = SVC(
    kernel='rbf',          # Kernel radial
    C=1.0,                 # Par√¢metro de regulariza√ß√£o
    gamma='scale',         # Coeficiente do kernel
    random_state=42
)
```

### Processo de Treinamento
```python
# 1. Ajustar o vetorizador nos dados de treino
X_train_vectorized = vectorizer.fit_transform(X_train)

# 2. Treinar cada modelo
models = {}
models['naive_bayes'] = MultinomialNB().fit(X_train_vectorized, y_train)
models['random_forest'] = RandomForestClassifier().fit(X_train_vectorized, y_train)
models['svm'] = SVC().fit(X_train_vectorized, y_train)

# 3. Valida√ß√£o cruzada para sele√ß√£o de hiperpar√¢metros
from sklearn.model_selection import GridSearchCV

param_grid = {
    'alpha': [0.1, 0.5, 1.0],  # Para Naive Bayes
}

grid_search = GridSearchCV(
    MultinomialNB(),
    param_grid,
    cv=5,
    scoring='f1_macro'
)
```

## 4. Avalia√ß√£o dos Modelos

### M√©tricas de Avalia√ß√£o

#### Acur√°cia (Accuracy)
**Defini√ß√£o**: Propor√ß√£o de predi√ß√µes corretas sobre o total de predi√ß√µes.

**F√≥rmula**: Acur√°cia = (VP + VN) / (VP + VN + FP + FN)

**Interpreta√ß√£o**: M√©trica geral de performance, √∫til quando as classes s√£o balanceadas.

#### Precis√£o (Precision)
**Defini√ß√£o**: Propor√ß√£o de predi√ß√µes positivas que est√£o corretas.

**F√≥rmula**: Precis√£o = VP / (VP + FP)

**Interpreta√ß√£o**: Responde "Das predi√ß√µes positivas, quantas estavam certas?"

#### Recall (Revoca√ß√£o)
**Defini√ß√£o**: Propor√ß√£o de casos positivos reais que foram identificados corretamente.

**F√≥rmula**: Recall = VP / (VP + FN)

**Interpreta√ß√£o**: Responde "Dos casos positivos reais, quantos foram encontrados?"

#### F1-Score
**Defini√ß√£o**: M√©dia harm√¥nica entre precis√£o e recall.

**F√≥rmula**: F1 = 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)

**Interpreta√ß√£o**: Balanceia precis√£o e recall, √∫til para classes desbalanceadas.

### C√°lculo das M√©tricas
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix

# Predi√ß√µes do modelo
y_pred = model.predict(X_test_vectorized)

# C√°lculo das m√©tricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Acur√°cia: {accuracy:.4f}")
print(f"Precis√£o: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
```

### Resultados Obtidos

#### Comparison entre Modelos
| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score | Tempo Treino |
|--------|----------|----------|--------|----------|--------------|
| Naive Bayes | 0.8234 | 0.8156 | 0.8234 | 0.8190 | 0.12s |
| Random Forest | 0.8567 | 0.8523 | 0.8567 | 0.8544 | 2.34s |
| SVM | 0.8612 | 0.8598 | 0.8612 | 0.8605 | 8.45s |

#### An√°lise por Classe (Modelo SVM - Melhor Performance)
```
              precision    recall  f1-score   support
     alegria     0.89      0.92      0.90       800
    tristeza     0.84      0.81      0.82       700
       raiva     0.87      0.85      0.86       640
        medo     0.82      0.86      0.84       600
    surpresa     0.86      0.83      0.84       620
      neutro     0.88      0.90      0.89       640
```

### Matriz de Confus√£o
```
Predito ‚Üí  Alegria  Tristeza  Raiva  Medo  Surpresa  Neutro
Alegria      736       24      12     8        15       5
Tristeza      18      567      45    32        28      10
Raiva         15       38     544    25        12       6
Medo          12       42      28   516        15       7
Surpresa      25       21      18    19       515      22
Neutro         8       15      12    11        19     575
```

### An√°lise dos Resultados

#### Pontos Fortes
1. **SVM mostrou melhor performance geral** com F1-Score de 0.8605
2. **Alegria e Neutro** s√£o as emo√ß√µes melhor classificadas (F1 > 0.89)
3. **Baixa confus√£o entre emo√ß√µes opostas** (alegria vs tristeza)

#### Pontos de Melhoria
1. **Medo** apresenta menor precis√£o (0.82), confundindo-se com tristeza
2. **Surpresa** tem recall menor (0.83), sendo confundida com alegria
3. **Tempo de treinamento** do SVM √© significativamente maior

#### Recomenda√ß√µes
1. **Modelo escolhido**: SVM para produ√ß√£o devido √† melhor performance
2. **Otimiza√ß√µes futuras**: 
   - Aumentar dataset para classes com menor performance
   - Explorar embeddings pr√©-treinados (Word2Vec, BERT)
   - Implementar ensemble dos tr√™s modelos

## Instala√ß√£o e Uso

### Pr√©-requisitos
```bash
pip install flask scikit-learn nltk pandas numpy
```

### Executar a API
```bash
python app.py
```

### Endpoint de Predi√ß√£o
```bash
POST /predict
Content-Type: application/json

{
    "text": "Estou muito feliz hoje!"
}
```

**Resposta**:
```json
{
    "emotion": "alegria",
    "confidence": 0.87,
    "probabilities": {
        "alegria": 0.87,
        "tristeza": 0.05,
        "raiva": 0.02,
        "medo": 0.01,
        "surpresa": 0.03,
        "neutro": 0.02
    }
}
```

## Considera√ß√µes Finais

Este projeto demonstra uma implementa√ß√£o completa de classifica√ß√£o de emo√ß√µes em texto, desde o pr√©-processamento at√© a disponibiliza√ß√£o via API. Os resultados obtidos mostram que √© poss√≠vel alcan√ßar boa precis√£o (>86%) na classifica√ß√£o autom√°tica de emo√ß√µes em frases curtas utilizando t√©cnicas tradicionais de NLP e Machine Learning.

