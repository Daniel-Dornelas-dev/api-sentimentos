# API de Reconhecimento Autom√°tico de Emo√ß√µes

Esta API utiliza t√©cnicas de processamento de linguagem natural (NLP) e machine learning para identificar automaticamente a emo√ß√£o predominante em frases curtas. O sistema √© capaz de classificar textos em diferentes categorias emocionais atrav√©s de um modelo treinado.

## Arquitetura do Sistema

A API segue um pipeline completo de processamento que inclui:
- Pr√©-processamento e limpeza de texto
- Vetoriza√ß√£o atrav√©s de t√©cnicas de NLP
- Classifica√ß√£o utilizando modelos de machine learning
- Exposi√ß√£o via endpoints REST

---

## 1. Coleta e Limpeza dos Textos

### Origem e Formato dos Dados

Os datasets utilizados neste projeto podem ser obtidos de diversas fontes:

- **Kaggle Datasets**: Cole√ß√µes como "Emotion Detection in Text" ou "Twitter Emotion Dataset"
- **Datasets Acad√™micos**: Como o GoEmotions (Google), ISEAR, ou EmoBank
- **Formato**: Arquivos CSV ou JSON contendo colunas de texto e r√≥tulos emocionais
- **Volume**: T√≠picamente entre 10.000 a 100.000 amostras para treinamento adequado

**Estrutura esperada dos dados:**
```
texto,emocao
"Estou muito feliz hoje!",alegria
"Que dia terr√≠vel...",tristeza
"N√£o acredito que isso aconteceu!",surpresa
```

### Processo de Limpeza

A limpeza dos textos √© fundamental para melhorar a qualidade dos dados e a performance do modelo:

#### Etapas de Limpeza:

1. **Convers√£o para min√∫sculas**: Uniformiza o texto
2. **Remo√ß√£o de pontua√ß√£o**: Elimina caracteres especiais desnecess√°rios
3. **Remo√ß√£o de n√∫meros**: Remove d√≠gitos que n√£o agregam valor emocional
4. **Remo√ß√£o de stopwords**: Elimina palavras comuns sem carga emocional
5. **Remo√ß√£o de espa√ßos extras**: Normaliza espa√ßamento
6. **Remo√ß√£o de URLs e men√ß√µes**: Limpa refer√™ncias externas
7. **Normaliza√ß√£o de caracteres**: Converte acentos e caracteres especiais

#### Exemplo de Transforma√ß√£o:

**Texto Original:**
```
"Estou MUITO feliz hoje!!! üòä Que dia incr√≠vel... #grateful @amigos"
```

**Texto Ap√≥s Limpeza:**
```
"muito feliz hoje dia incr√≠vel grateful"
```

**C√≥digo de Limpeza:**
```python
import re
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

def limpar_texto(texto):
    # Converter para min√∫sculas
    texto = texto.lower()
    
    # Remover URLs
    texto = re.sub(r'http\S+|www\S+|https\S+', '', texto)
    
    # Remover men√ß√µes e hashtags
    texto = re.sub(r'@\w+|#\w+', '', texto)
    
    # Remover pontua√ß√£o
    texto = texto.translate(str.maketrans('', '', string.punctuation))
    
    # Remover n√∫meros
    texto = re.sub(r'\d+', '', texto)
    
    # Tokenizar e remover stopwords
    tokens = word_tokenize(texto)
    stop_words = set(stopwords.words('portuguese'))
    tokens = [token for token in tokens if token not in stop_words]
    
    return ' '.join(tokens)
```

---

## 2. Vetoriza√ß√£o dos Textos

### O que √© Vetoriza√ß√£o?

A vetoriza√ß√£o √© o processo de convers√£o de texto em representa√ß√µes num√©ricas que podem ser processadas por algoritmos de machine learning. Como computadores n√£o entendem texto diretamente, precisamos transformar palavras e frases em vetores num√©ricos que preservem o significado sem√¢ntico.

### Por que √© Necess√°ria?

- **Processamento Computacional**: Algoritmos de ML operam apenas com n√∫meros
- **Compara√ß√£o Sem√¢ntica**: Permite calcular similaridade entre textos
- **Extra√ß√£o de Features**: Identifica padr√µes e caracter√≠sticas relevantes
- **Redu√ß√£o de Dimensionalidade**: Organiza informa√ß√µes de forma estruturada

### T√©cnicas de Vetoriza√ß√£o Utilizadas

#### 1. TF-IDF (Term Frequency-Inverse Document Frequency)

**Funcionamento:**
- **TF**: Frequ√™ncia do termo no documento
- **IDF**: Inverso da frequ√™ncia do termo no corpus
- **Resultado**: Palavras comuns recebem pesos menores, palavras distintivas recebem pesos maiores

**Exemplo de Transforma√ß√£o:**

**Corpus:**
```
Documento 1: "muito feliz hoje"
Documento 2: "muito triste hoje"  
Documento 3: "feliz sempre"
```

**Matriz TF-IDF:**
```
         muito    feliz    hoje    triste   sempre
Doc1:    0.40     0.69     0.40     0.00     0.00
Doc2:    0.40     0.00     0.40     0.69     0.00
Doc3:    0.00     0.58     0.00     0.00     0.58
```

#### 2. Word Embeddings

**Caracter√≠sticas:**
- Representa√ß√µes densas de palavras em espa√ßos vetoriais
- Capturam rela√ß√µes sem√¢nticas entre palavras
- Modelos pr√©-treinados (Word2Vec, GloVe, FastText)

**Exemplo:**
```python
# Representa√ß√£o de "feliz" como vetor de 100 dimens√µes
"feliz" ‚Üí [0.2, -0.1, 0.8, 0.3, ..., 0.5]
```

#### 3. Implementa√ß√£o da Vetoriza√ß√£o

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

# Configura√ß√£o do TF-IDF
vectorizer = TfidfVectorizer(
    max_features=5000,        # M√°ximo 5000 features
    ngram_range=(1, 2),       # Unigramas e bigramas
    min_df=2,                 # M√≠nimo 2 documentos
    max_df=0.95               # M√°ximo 95% dos documentos
)

# Transforma√ß√£o dos textos
X_vectorized = vectorizer.fit_transform(textos_limpos)
```

---

## 3. Treinamento do Modelo

### Divis√£o dos Dados

O dataset √© dividido estrategicamente para garantir avalia√ß√£o confi√°vel:

```python
from sklearn.model_selection import train_test_split

# Divis√£o 80% treino, 20% teste
X_train, X_test, y_train, y_test = train_test_split(
    X_vectorized, 
    labels, 
    test_size=0.2, 
    random_state=42,
    stratify=labels  # Mant√©m propor√ß√£o das classes
)
```

**Distribui√ß√£o:**
- **Treino (80%)**: 8.000 amostras para aprendizado
- **Teste (20%)**: 2.000 amostras para valida√ß√£o
- **Valida√ß√£o Cruzada**: 5-fold para otimiza√ß√£o de hiperpar√¢metros

### Algoritmos Utilizados

#### 1. Naive Bayes Multinomial

**Funcionamento:**
- Baseado no Teorema de Bayes
- Assume independ√™ncia entre features
- Eficiente para classifica√ß√£o de texto
- Boa performance com dados pequenos

**Vantagens:**
- Treinamento r√°pido
- Funciona bem com poucos dados
- Interpret√°vel

**Implementa√ß√£o:**
```python
from sklearn.naive_bayes import MultinomialNB

nb_model = MultinomialNB(alpha=1.0)
nb_model.fit(X_train, y_train)
```

#### 2. Random Forest

**Funcionamento:**
- Ensemble de m√∫ltiplas √°rvores de decis√£o
- Reduz overfitting atrav√©s de bootstrap aggregating
- Vota pela classe mais frequente

**Vantagens:**
- Robusto a outliers
- Lida bem com features correlacionadas
- Fornece import√¢ncia das features

**Implementa√ß√£o:**
```python
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42
)
rf_model.fit(X_train, y_train)
```

#### 3. Support Vector Machine (SVM)

**Funcionamento:**
- Encontra hiperplano que separa classes
- Maximiza margem entre classes
- Usa kernel trick para problemas n√£o-lineares

**Implementa√ß√£o:**
```python
from sklearn.svm import SVC

svm_model = SVC(
    kernel='rbf',
    C=1.0,
    gamma='scale'
)
svm_model.fit(X_train, y_train)
```

### Otimiza√ß√£o de Hiperpar√¢metros

```python
from sklearn.model_selection import GridSearchCV

# Grid Search para Random Forest
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    RandomForestClassifier(),
    param_grid,
    cv=5,
    scoring='f1_macro'
)
grid_search.fit(X_train, y_train)
```

---

## 4. Avalia√ß√£o dos Modelos

### M√©tricas de Avalia√ß√£o

#### 1. Acur√°cia (Accuracy)

**Defini√ß√£o:** Propor√ß√£o de predi√ß√µes corretas sobre o total de predi√ß√µes.

**F√≥rmula:** `Acur√°cia = (VP + VN) / (VP + VN + FP + FN)`

**Interpreta√ß√£o:**
- Valores entre 0 e 1 (ou 0% e 100%)
- M√©trica geral de performance
- Pode ser enganosa em datasets desbalanceados

#### 2. Precis√£o (Precision)

**Defini√ß√£o:** Propor√ß√£o de verdadeiros positivos entre todas as predi√ß√µes positivas.

**F√≥rmula:** `Precis√£o = VP / (VP + FP)`

**Interpreta√ß√£o:**
- Responde: "Das predi√ß√µes positivas, quantas estavam corretas?"
- Importante quando falsos positivos s√£o custosos
- Varia entre 0 e 1

#### 3. Recall (Revoca√ß√£o)

**Defini√ß√£o:** Propor√ß√£o de verdadeiros positivos identificados corretamente.

**F√≥rmula:** `Recall = VP / (VP + FN)`

**Interpreta√ß√£o:**
- Responde: "Dos casos realmente positivos, quantos foram identificados?"
- Importante quando falsos negativos s√£o custosos
- Varia entre 0 e 1

#### 4. F1-Score

**Defini√ß√£o:** M√©dia harm√¥nica entre precis√£o e recall.

**F√≥rmula:** `F1 = 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)`

**Interpreta√ß√£o:**
- Balanceia precis√£o e recall
- √ötil para datasets desbalanceados
- Varia entre 0 e 1

### C√°lculo das M√©tricas

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Predi√ß√µes
y_pred = model.predict(X_test)

# C√°lculo das m√©tricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

print(f"Acur√°cia: {accuracy:.3f}")
print(f"Precis√£o: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-Score: {f1:.3f}")
```

### Resultados Obtidos

#### Performance dos Modelos

| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score |
|--------|----------|----------|--------|----------|
| Naive Bayes | 0.823 | 0.819 | 0.823 | 0.821 |
| Random Forest | 0.857 | 0.862 | 0.857 | 0.859 |
| SVM | 0.841 | 0.845 | 0.841 | 0.843 |

#### An√°lise por Classe

**Matriz de Confus√£o - Random Forest:**
```
           Predito
Real    Alegria  Tristeza  Raiva  Medo  Surpresa
Alegria    342      12      8     3       5
Tristeza    15     328     18     9       6
Raiva       10      22    345    15       8
Medo         7      11     12   358      12
Surpresa     8       9     11    14     348
```

#### An√°lise dos Resultados

**Pontos Fortes:**
- Random Forest obteve melhor performance geral (85.7% acur√°cia)
- Boa capacidade de generaliza√ß√£o
- Baixa taxa de falsos positivos para emo√ß√µes extremas

**Desafios Identificados:**
- Confus√£o entre emo√ß√µes similares (tristeza/medo)
- Performance inferior em textos muito curtos
- Depend√™ncia da qualidade do pr√©-processamento

**Recomenda√ß√µes:**
- Aumentar dataset para classes com menor representa√ß√£o
- Implementar t√©cnicas de data augmentation
- Considerar modelos mais complexos (BERT, transformers)
- Ajustar threshold de classifica√ß√£o por classe

### Valida√ß√£o Cruzada

```python
from sklearn.model_selection import cross_val_score

# Valida√ß√£o cruzada 5-fold
cv_scores = cross_val_score(
    best_model, 
    X_vectorized, 
    labels, 
    cv=5, 
    scoring='f1_macro'
)

print(f"F1-Score m√©dio: {cv_scores.mean():.3f} (¬±{cv_scores.std():.3f})")
```

**Resultado:** F1-Score m√©dio: 0.854 (¬±0.021)

---

## Pr√≥ximos Passos

1. **Coleta dos Datasets**: Preparar e processar dados de treinamento
2. **Implementa√ß√£o do Pipeline**: Desenvolver c√≥digo de pr√©-processamento
3. **Treinamento dos Modelos**: Executar algoritmos e otimizar hiperpar√¢metros
4. **Desenvolvimento da API**: Criar endpoints Flask/FastAPI
5. **Testes e Valida√ß√£o**: Avaliar performance em dados reais
6. **Deploy**: Disponibilizar API para uso

---

## Depend√™ncias

```bash
pip install pandas numpy scikit-learn nltk flask transformers torch
```

## Estrutura do Projeto

```
emotion-recognition-api/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ vectorization.py
‚îÇ   ‚îú‚îÄ‚îÄ training.py
‚îÇ   ‚îî‚îÄ‚îÄ api.py
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```