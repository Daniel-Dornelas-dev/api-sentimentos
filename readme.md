# API de Reconhecimento de Emo√ß√µes

Sistema de an√°lise autom√°tica de emo√ß√µes em frases curtas utilizando Machine Learning. A API recebe uma frase via endpoint e retorna a emo√ß√£o predominante detectada.

## üîß Tecnologias Utilizadas

- **Python 3.8+**
- **Flask** (API REST)
- **scikit-learn** (ML)
- **NLTK** (processamento de texto)
- **pandas** (manipula√ß√£o de dados)
- **numpy** (opera√ß√µes num√©ricas)

---

## 1. Coleta e Limpeza dos Textos

### 1.1 Origem dos Dados

O dataset utilizado cont√©m frases rotuladas com emo√ß√µes b√°sicas:
- **Formato**: CSV com colunas `text` e `emotion`
- **Volume**: ~10.000 frases
- **Categorias**: alegria, tristeza, raiva, medo, surpresa, neutro

### 1.2 Processo de Limpeza

O pr√©-processamento segue as seguintes etapas:

1. **Convers√£o para min√∫sculas**
2. **Remo√ß√£o de pontua√ß√£o** (exceto emoticons)
3. **Remo√ß√£o de stopwords** (palavras sem valor sem√¢ntico)
4. **Tokeniza√ß√£o** (divis√£o em palavras)
5. **Stemming** (redu√ß√£o √†s ra√≠zes das palavras)

### 1.3 Exemplo Pr√°tico

```python
# Texto original
"Estou MUITO feliz com este resultado! üòä"

# Ap√≥s limpeza
"muito feliz result"
```

**Processo detalhado:**
- Min√∫sculas: "estou muito feliz com este resultado! üòä"
- Sem pontua√ß√£o: "estou muito feliz com este resultado üòä"
- Sem stopwords: "muito feliz resultado üòä"
- Stemming: "muito feliz result"

---

## 2. Vetoriza√ß√£o dos Textos

### 2.1 Conceito

Vetoriza√ß√£o transforma texto em representa√ß√£o num√©rica para que algoritmos de ML possam process√°-lo. Cada palavra/frase torna-se um vetor de n√∫meros que representa suas caracter√≠sticas sem√¢nticas.

### 2.2 M√©todos Implementados

#### TF-IDF (Term Frequency-Inverse Document Frequency)
- **TF**: Frequ√™ncia do termo no documento
- **IDF**: Import√¢ncia do termo no corpus
- **F√≥rmula**: TF-IDF = TF √ó log(N/df)

#### Word Embeddings
- Representa√ß√£o densa em espa√ßo vetorial
- Captura rela√ß√µes sem√¢nticas entre palavras
- Dimensionalidade: 100-300 dimens√µes

### 2.3 Exemplo de Transforma√ß√£o

```python
# Frase: "muito feliz"
# TF-IDF (vocabul√°rio simplificado)
{
    "muito": 0.47,
    "feliz": 0.88,
    "triste": 0.0,
    "raiva": 0.0
}

# Resultado: [0.47, 0.88, 0.0, 0.0, ...]
```

---

## 3. Treinamento do Modelo

### 3.1 Divis√£o dos Dados

- **Treino**: 80% (8.000 frases)
- **Teste**: 20% (2.000 frases)
- **Valida√ß√£o**: Estratificada por classe

### 3.2 Algoritmos Utilizados

#### Naive Bayes Multinomial
- **Funcionamento**: Calcula probabilidade de cada classe usando teorema de Bayes
- **Vantagem**: Eficiente para classifica√ß√£o de texto
- **F√≥rmula**: P(classe|texto) = P(texto|classe) √ó P(classe) / P(texto)

#### Random Forest
- **Funcionamento**: Ensemble de √°rvores de decis√£o
- **Par√¢metros**: 100 √°rvores, profundidade m√°xima = 20
- **Vantagem**: Reduz overfitting e melhora generaliza√ß√£o

#### BERT (Bidirectional Encoder Representations)
- **Funcionamento**: Transformer pr√©-treinado com aten√ß√£o bidirecional
- **Fine-tuning**: Ajuste das camadas finais para classifica√ß√£o de emo√ß√µes
- **Vantagem**: Compreens√£o contextual avan√ßada

### 3.3 Processo de Treinamento

```python
# Exemplo simplificado
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# Otimiza√ß√£o de hiperpar√¢metros
param_grid = {'alpha': [0.1, 1.0, 10.0]}
grid_search = GridSearchCV(model, param_grid, cv=5)
```

---

## 4. Avalia√ß√£o dos Modelos

### 4.1 M√©tricas Utilizadas

#### Acur√°cia
- **Defini√ß√£o**: Propor√ß√£o de predi√ß√µes corretas
- **F√≥rmula**: (VP + VN) / (VP + VN + FP + FN)
- **Interpreta√ß√£o**: Medida geral de performance

#### Precis√£o
- **Defini√ß√£o**: Propor√ß√£o de predi√ß√µes positivas corretas
- **F√≥rmula**: VP / (VP + FP)
- **Interpreta√ß√£o**: Qualidade das predi√ß√µes positivas

#### Recall (Sensibilidade)
- **Defini√ß√£o**: Propor√ß√£o de casos positivos identificados
- **F√≥rmula**: VP / (VP + FN)
- **Interpreta√ß√£o**: Capacidade de encontrar casos positivos

#### F1-Score
- **Defini√ß√£o**: M√©dia harm√¥nica entre precis√£o e recall
- **F√≥rmula**: 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)

### 4.2 Resultados Obtidos

| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score |
|--------|----------|----------|--------|----------|
| Naive Bayes | 0.82 | 0.81 | 0.80 | 0.80 |
| Random Forest | 0.85 | 0.84 | 0.83 | 0.83 |
| BERT | 0.91 | 0.90 | 0.89 | 0.89 |

### 4.3 An√°lise dos Resultados

**Pontos Fortes:**
- BERT apresentou melhor performance geral
- Boa capacidade de generaliza√ß√£o em todas as classes
- Baixa taxa de falsos positivos

**Limita√ß√µes:**
- Dificuldade em distinguir tristeza/melancolia
- Performance inferior em textos muito curtos (<3 palavras)
- Sensibilidade a contexto cultural em express√µes idiom√°ticas

**Recomenda√ß√£o:** BERT como modelo principal, com Random Forest como fallback para casos de baixa confian√ßa.

---

## üöÄ Uso da API

```python
# Endpoint principal
POST /predict
{
    "text": "Estou muito feliz hoje!"
}

# Resposta
{
    "emotion": "alegria",
    "confidence": 0.89,
    "processing_time": 0.02
}
```